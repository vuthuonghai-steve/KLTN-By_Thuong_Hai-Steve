#!/usr/bin/env python3
"""
build_registry.py â€” Auto-Indexing Script for flow-design-analyst skill

Má»¥c Ä‘Ã­ch:
    QuÃ©t tá»± Ä‘á»™ng toÃ n bá»™ thÆ° má»¥c tÃ i liá»‡u cá»§a má»™t dá»± Ã¡n (docs_dir),
    trÃ­ch xuáº¥t cÃ¡c thÃ nh pháº§n cÃ³ cáº¥u trÃºc tá»« file Markdown, vÃ  sinh ra
    file `project-registry.json` â€” nguá»“n tri thá»©c dá»± Ã¡n cho Skill sá»­ dá»¥ng
    á»Ÿ Phase 0 DETECT vÃ  Phase 1 DISCOVER.

TrÃ­ch xuáº¥t:
    - Headings (H1, H2, H3) â†’ táº¡o outline cáº¥u trÃºc tÃ i liá»‡u
    - UC-ID references (UC01, UC-1, USE-CASE-01, v.v.)
    - Actor mentions (User, Admin, Guest, System, DB...)
    - Keywords tá»« heading vÃ  context xung quanh
    - Metadata: file path, last modified, line count

Sá»­ dá»¥ng:
    python build_registry.py --docs-dir ./Docs --output ./project-registry.json
    python build_registry.py --docs-dir ./Docs --output ./project-registry.json --verbose
    python build_registry.py --docs-dir ./Docs --include "specs/**" --include "user-stories/**"

Output format: project-registry.json (xem Â§5 trong code)

Exit codes:
    0 = ThÃ nh cÃ´ng, sinh Ä‘Æ°á»£c registry file
    1 = Lá»—i (khÃ´ng tÃ¬m tháº¥y docs_dir, khÃ´ng cÃ³ file .md nÃ o, v.v.)
"""

import re
import os
import sys
import json
import argparse
from pathlib import Path
from datetime import datetime
from fnmatch import fnmatch
from dataclasses import dataclass, field, asdict
from typing import Optional


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Â§1. CONSTANTS â€” Táº­p há»£p patterns trÃ­ch xuáº¥t
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Pattern nháº­n diá»‡n UC-ID (linh hoáº¡t theo nhiá»u convention phá»• biáº¿n)
UC_ID_PATTERNS = [
    r"\bUC[\s\-_]?\d{1,3}\b",          # UC01, UC-01, UC_01, UC 01
    r"\bUC[\s\-_]?\d{1,3}[a-zA-Z]?\b", # UC01a, UC-01-A
    r"\bUSE[\s\-_]CASE[\s\-_]\d{1,3}\b", # USE-CASE-01
    r"\b(?:UC|F|FR|US|USER[\s\-]?STORY)[\s\-_]?\d+\b",  # FR-1, US-3, F01
]
UC_COMPILED = [re.compile(p, re.IGNORECASE) for p in UC_ID_PATTERNS]

# Keywords actor â€” nháº­n diá»‡n "diá»…n viÃªn" trong flow
ACTOR_KEYWORDS = [
    "user", "guest", "member", "admin", "administrator",
    "system", "server", "backend", "api", "service",
    "database", "db", "mongodb", "postgres", "mysql", "redis",
    "client", "browser", "mobile", "frontend",
    "ngÆ°á»i dÃ¹ng", "quáº£n trá»‹ viÃªn", "há»‡ thá»‘ng", "mÃ¡y chá»§", "cÆ¡ sá»Ÿ dá»¯ liá»‡u",
    # CÃ³ thá»ƒ má»Ÿ rá»™ng theo dá»± Ã¡n
]

# Stop words â€” tá»« khÃ´ng cÃ³ giÃ¡ trá»‹ lÃ m keyword
STOP_WORDS = {
    "a", "an", "the", "and", "or", "of", "to", "in", "for", "on", "at",
    "is", "are", "was", "be", "been", "being", "have", "has", "with",
    "this", "that", "will", "can", "may", "from", "by", "as", "it",
    "not", "but", "all", "so", "do", "its", "if", "when", "where",
    "how", "what", "which", "who", "then", "than", "into", "over",
    "more", "also", "any", "each", "their", "them", "they",
    # Tiáº¿ng Viá»‡t stop words
    "vÃ ", "hoáº·c", "cá»§a", "Ä‘á»ƒ", "trong", "lÃ ", "vá»›i", "cÃ¡c", "má»™t",
    "táº¥t", "cáº£", "Ä‘áº¿n", "tá»«", "theo", "náº¿u", "khi", "thÃ¬", "cho",
    "Ä‘Æ°á»£c", "bá»Ÿi", "do", "vá»", "cÃ³", "nÃ y", "Ä‘Ã³", "nhÆ°", "vÃ o",
}

# Pattern nháº­n diá»‡n heading Markdown
HEADING_PATTERN = re.compile(r"^(#{1,6})\s+(.+)$")

# Pattern nháº­n diá»‡n "Use Case" title trong heading
UC_TITLE_HINTS = re.compile(
    r"(?:use\s*case|use-case|uc|tÃ­nh\s*nÄƒng|chá»©c\s*nÄƒng|luá»“ng|flow|scenario|feature)",
    re.IGNORECASE
)

# Pattern trÃ­ch xuáº¥t tá»« cÃ³ nghÄ©a (min 3 kÃ½ tá»±, tiáº¿ng Anh hoáº·c Viá»‡t)
TOKEN_PATTERN = re.compile(r"\b[a-zA-ZÃ€-á»¹][a-zA-ZÃ€-á»¹]{2,}\b")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Â§2. DATA MODELS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@dataclass
class HeadingNode:
    """Má»™t heading trong file Markdown"""
    level: int          # 1â€“6 (H1â€“H6)
    text: str           # Ná»™i dung heading
    line_number: int    # DÃ²ng trong file
    uc_ids: list[str] = field(default_factory=list)    # UC-ID trÃ­ch xuáº¥t tá»« heading
    actors: list[str] = field(default_factory=list)    # Actors trÃ­ch xuáº¥t
    keywords: list[str] = field(default_factory=list)  # Keywords trÃ­ch xuáº¥t
    context_lines: list[str] = field(default_factory=list)  # 3 dÃ²ng context sau heading


@dataclass
class FileEntry:
    """Äáº¡i diá»‡n cho má»™t file .md Ä‘Ã£ Ä‘Æ°á»£c index"""
    relative_path: str          # ÄÆ°á»ng dáº«n tÆ°Æ¡ng Ä‘á»‘i tá»« docs_dir
    absolute_path: str          # ÄÆ°á»ng dáº«n tuyá»‡t Ä‘á»‘i
    file_name: str              # TÃªn file (khÃ´ng cÃ³ extension)
    last_modified: str          # ISO 8601
    line_count: int
    h1_title: Optional[str]     # H1 Ä‘áº§u tiÃªn cá»§a file (main title)
    uc_ids: list[str] = field(default_factory=list)    # Táº¥t cáº£ UC-ID trong file
    actors: list[str] = field(default_factory=list)    # Táº¥t cáº£ actors trong file
    keywords: list[str] = field(default_factory=list)  # Top keywords
    headings: list[dict] = field(default_factory=list) # List HeadingNode dáº¡ng dict
    is_spec: bool = False        # CÃ³ pháº£i spec file khÃ´ng?
    is_user_story: bool = False  # CÃ³ pháº£i user story khÃ´ng?
    is_use_case: bool = False    # CÃ³ pháº£i use case diagram khÃ´ng?


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Â§3. EXTRACTION FUNCTIONS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def extract_uc_ids(text: str) -> list[str]:
    """TrÃ­ch xuáº¥t táº¥t cáº£ UC-ID tá»« Ä‘oáº¡n text"""
    found = set()
    for pattern in UC_COMPILED:
        for m in pattern.finditer(text):
            # Normalize: chuyá»ƒn thÃ nh dáº¡ng chuáº©n "UC01"
            raw = m.group(0).strip()
            normalized = re.sub(r"[\s\-_]", "", raw).upper()
            # Chá»‰ giá»¯ láº¡i dáº¡ng UCXX, FRXX, USXX
            if re.match(r"^(UC|FR|US|F)\d+", normalized):
                found.add(normalized)
    return sorted(found)


def extract_actors(text: str) -> list[str]:
    """TrÃ­ch xuáº¥t tÃªn actors Ä‘Æ°á»£c nháº¯c Ä‘áº¿n trong text"""
    found = set()
    text_lower = text.lower()
    for actor in ACTOR_KEYWORDS:
        if actor in text_lower:
            found.add(actor.title())  # Capitalize: "user" â†’ "User"
    return sorted(found)


def extract_keywords(text: str, top_n: int = 10) -> list[str]:
    """
    TrÃ­ch xuáº¥t keywords cÃ³ Ã½ nghÄ©a tá»« text.
    Loáº¡i bá» stop words, Ä‘áº¿m táº§n suáº¥t, tráº£ top_n tá»« phá»• biáº¿n nháº¥t.
    """
    tokens = TOKEN_PATTERN.findall(text.lower())
    freq: dict[str, int] = {}
    for token in tokens:
        if token not in STOP_WORDS and len(token) > 2:
            freq[token] = freq.get(token, 0) + 1
    sorted_tokens = sorted(freq.items(), key=lambda x: x[1], reverse=True)
    return [word for word, _ in sorted_tokens[:top_n]]


def classify_file(relative_path: str, h1_title: Optional[str]) -> tuple[bool, bool, bool]:
    """
    PhÃ¢n loáº¡i loáº¡i file: is_spec, is_user_story, is_use_case.
    Dá»±a trÃªn tÃªn file vÃ  H1 title.
    """
    path_lower = relative_path.lower()
    title_lower = (h1_title or "").lower()

    spec_hints = ["spec", "specification", "requirement", "prd", "srs", "feature"]
    us_hints = ["user-stor", "user_stor", "stories", "userstory", "us-", "sprint"]
    uc_hints = ["use-case", "use_case", "usecase", "uc-", "diagram"]

    is_spec = any(h in path_lower or h in title_lower for h in spec_hints)
    is_user_story = any(h in path_lower or h in title_lower for h in us_hints)
    is_use_case = any(h in path_lower or h in title_lower for h in uc_hints)

    return is_spec, is_user_story, is_use_case


def parse_markdown_file(
    file_path: Path,
    docs_dir: Path,
    context_lines_count: int = 3,
    verbose: bool = False,
) -> Optional[FileEntry]:
    """
    Parse má»™t file Markdown vÃ  tráº£ vá» FileEntry Ä‘áº§y Ä‘á»§.
    TrÃ­ch xuáº¥t: headings, UC-ID, actors, keywords, metadata.
    """
    try:
        content = file_path.read_text(encoding="utf-8", errors="replace")
    except OSError as e:
        if verbose:
            print(f"  âš ï¸  KhÃ´ng Ä‘á»c Ä‘Æ°á»£c {file_path}: {e}", file=sys.stderr)
        return None

    lines = content.splitlines()
    line_count = len(lines)
    relative_path = str(file_path.relative_to(docs_dir)).replace("\\", "/")

    stat = file_path.stat()
    last_modified = datetime.fromtimestamp(stat.st_mtime).isoformat()

    # TrÃ­ch xuáº¥t headings
    headings: list[HeadingNode] = []
    h1_title: Optional[str] = None

    for i, line in enumerate(lines):
        m = HEADING_PATTERN.match(line.strip())
        if not m:
            continue

        level = len(m.group(1))
        text = m.group(2).strip()

        # H1 Ä‘áº§u tiÃªn = main title
        if level == 1 and h1_title is None:
            h1_title = text

        # Context: láº¥y context_lines_count dÃ²ng sau heading (khÃ´ng pháº£i heading)
        context = []
        for j in range(i + 1, min(i + 1 + context_lines_count * 2, len(lines))):
            stripped = lines[j].strip()
            if not stripped or HEADING_PATTERN.match(stripped):
                break
            context.append(stripped)
            if len(context) >= context_lines_count:
                break

        context_text = " ".join(context)
        combined = f"{text} {context_text}"

        node = HeadingNode(
            level=level,
            text=text,
            line_number=i + 1,
            uc_ids=extract_uc_ids(combined),
            actors=extract_actors(combined),
            keywords=extract_keywords(combined, top_n=5),
            context_lines=context,
        )
        headings.append(node)

    # Tá»•ng há»£p tá»« toÃ n file
    all_uc_ids = sorted(set(uid for h in headings for uid in h.uc_ids))
    all_actors = sorted(set(a for h in headings for a in h.actors))

    # Keywords tá»« toÃ n bá»™ ná»™i dung (top 15)
    all_keywords = extract_keywords(content, top_n=15)

    # PhÃ¢n loáº¡i loáº¡i file
    is_spec, is_user_story, is_use_case = classify_file(relative_path, h1_title)

    return FileEntry(
        relative_path=relative_path,
        absolute_path=str(file_path),
        file_name=file_path.stem,
        last_modified=last_modified,
        line_count=line_count,
        h1_title=h1_title,
        uc_ids=all_uc_ids,
        actors=all_actors,
        keywords=all_keywords,
        headings=[asdict(h) for h in headings],
        is_spec=is_spec,
        is_user_story=is_user_story,
        is_use_case=is_use_case,
    )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Â§4. SCANNER â€” Duyá»‡t docs_dir vÃ  index táº¥t cáº£ file .md
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def should_include_file(file_path: Path, docs_dir: Path, include_patterns: list[str]) -> bool:
    """
    Kiá»ƒm tra xem file cÃ³ nÃªn Ä‘Æ°á»£c index khÃ´ng, dá»±a trÃªn include_patterns.
    Náº¿u khÃ´ng cÃ³ pattern nÃ o, index táº¥t cáº£ .md files.
    """
    if not include_patterns:
        return True
    rel = str(file_path.relative_to(docs_dir)).replace("\\", "/")
    return any(fnmatch(rel, pat) for pat in include_patterns)


def scan_docs_dir(
    docs_dir: Path,
    include_patterns: list[str],
    exclude_dirs: list[str],
    verbose: bool = False,
) -> list[FileEntry]:
    """
    Duyá»‡t Ä‘á»‡ quy docs_dir, parse má»i file .md vÃ  tráº£ list FileEntry.
    """
    entries: list[FileEntry] = []
    skip_dirs = {".git", "node_modules", "__pycache__", ".agent", ".skill-context"}
    skip_dirs.update(d.lower() for d in exclude_dirs)

    all_md_files = []
    for root, dirs, files in os.walk(docs_dir):
        # Loáº¡i bá» thÆ° má»¥c khÃ´ng cáº§n scan
        dirs[:] = [d for d in dirs if d.lower() not in skip_dirs]

        for filename in files:
            if not filename.endswith(".md"):
                continue
            file_path = Path(root) / filename
            if should_include_file(file_path, docs_dir, include_patterns):
                all_md_files.append(file_path)

    total = len(all_md_files)
    if verbose:
        print(f"ğŸ“‚ TÃ¬m tháº¥y {total} file .md trong '{docs_dir}'")

    for i, file_path in enumerate(sorted(all_md_files), 1):
        rel = str(file_path.relative_to(docs_dir))
        if verbose:
            print(f"  [{i:03d}/{total:03d}] Parsing: {rel}")

        entry = parse_markdown_file(file_path, docs_dir, verbose=verbose)
        if entry:
            entries.append(entry)

    return entries


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Â§5. REGISTRY BUILDER â€” Tá»•ng há»£p thÃ nh project-registry.json
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def build_registry(
    docs_dir: Path,
    output_path: Path,
    include_patterns: list[str],
    exclude_dirs: list[str],
    project_name: Optional[str],
    verbose: bool,
) -> dict:
    """
    Orchestrate scan â†’ parse â†’ tá»•ng há»£p â†’ ghi JSON.

    Output format (project-registry.json):
    {
      "meta": {
        "generated_at": "ISO-8601",
        "docs_dir": "...",
        "project_name": "...",
        "total_files": N,
        "tool_version": "1.0.0"
      },
      "summary": {
        "all_uc_ids": [...],     # Táº¥t cáº£ UC-ID tÃ¬m Ä‘Æ°á»£c
        "all_actors": [...],     # Táº¥t cáº£ actors tÃ¬m Ä‘Æ°á»£c
        "file_types": {
          "spec_files": [...],        # Relative paths cá»§a spec files
          "user_story_files": [...],  # Relative paths cá»§a US files
          "use_case_files": [...],    # Relative paths cá»§a UC diagram files
          "other_files": [...]        # CÃ²n láº¡i
        }
      },
      "files": [
        {
          "relative_path": "...",
          "file_name": "...",
          "h1_title": "...",
          "uc_ids": [...],
          "actors": [...],
          "keywords": [...],
          "is_spec": true/false,
          "is_user_story": true/false,
          "is_use_case": true/false,
          "last_modified": "...",
          "line_count": N,
          "headings": [
            {
              "level": 2,
              "text": "...",
              "line_number": N,
              "uc_ids": [...],
              "actors": [...],
              "keywords": [...],
              "context_lines": [...]
            }
          ]
        },
        ...
      ]
    }
    """
    print(f"\nğŸ” build_registry.py â€” Project Document Auto-Indexer")
    print(f"   docs_dir : {docs_dir}")
    print(f"   output   : {output_path}")
    if include_patterns:
        print(f"   include  : {include_patterns}")
    print()

    # Scan & parse
    entries = scan_docs_dir(docs_dir, include_patterns, exclude_dirs, verbose)

    if not entries:
        print("âŒ KhÃ´ng tÃ¬m tháº¥y file .md nÃ o cÃ³ thá»ƒ index.", file=sys.stderr)
        sys.exit(1)

    # Tá»•ng há»£p summary
    all_uc_ids = sorted(set(uid for e in entries for uid in e.uc_ids))
    all_actors = sorted(set(a for e in entries for a in e.actors))

    spec_files = [e.relative_path for e in entries if e.is_spec]
    us_files = [e.relative_path for e in entries if e.is_user_story]
    uc_files = [e.relative_path for e in entries if e.is_use_case]
    other_files = [
        e.relative_path for e in entries
        if not e.is_spec and not e.is_user_story and not e.is_use_case
    ]

    # Build registry dict
    registry = {
        "meta": {
            "generated_at": datetime.now().isoformat(),
            "docs_dir": str(docs_dir),
            "project_name": project_name or docs_dir.parent.name,
            "total_files": len(entries),
            "tool_version": "1.1.0",
        },
        "summary": {
            "all_uc_ids": all_uc_ids,
            "all_actors": all_actors,
            "file_types": {
                "spec_files": spec_files,
                "user_story_files": us_files,
                "use_case_files": uc_files,
                "other_files": other_files,
            },
        },
        "files": [asdict(e) for e in entries],
    }

    # Ghi file JSON
    output_path.parent.mkdir(parents=True, exist_ok=True)
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(registry, f, ensure_ascii=False, indent=2)

    return registry


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Â§6. REPORT â€” In káº¿t quáº£ tÃ³m táº¯t sau khi build
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def print_report(registry: dict) -> None:
    meta = registry["meta"]
    summary = registry["summary"]
    files = registry["files"]

    print(f"\n{'='*55}")
    print(f"  ğŸ“‹ REGISTRY BUILD REPORT")
    print(f"{'='*55}")
    print(f"  Project      : {meta['project_name']}")
    print(f"  Generated at : {meta['generated_at'][:19]}")
    print(f"  Total files  : {meta['total_files']}")
    print()

    ft = summary["file_types"]
    print(f"  ğŸ“ File Classification:")
    print(f"     Spec files       : {len(ft['spec_files'])}")
    print(f"     User story files : {len(ft['user_story_files'])}")
    print(f"     Use case files   : {len(ft['use_case_files'])}")
    print(f"     Other files      : {len(ft['other_files'])}")
    print()

    uc_ids = summary["all_uc_ids"]
    if uc_ids:
        print(f"  ğŸ”– UC-IDs found ({len(uc_ids)}): {', '.join(uc_ids[:20])}")
        if len(uc_ids) > 20:
            print(f"     ... vÃ  {len(uc_ids) - 20} UC-ID khÃ¡c")
    else:
        print(f"  ğŸ”– UC-IDs: KhÃ´ng tÃ¬m tháº¥y UC-ID nÃ o")
    print()

    actors = summary["all_actors"]
    if actors:
        print(f"  ğŸ‘¥ Actors found: {', '.join(actors)}")
    print()

    # Top 5 files nhá»u heading nháº¥t (phá»©c táº¡p nháº¥t)
    top_files = sorted(files, key=lambda f: len(f.get("headings", [])), reverse=True)[:5]
    print(f"  ğŸ“Š Top files (by heading count):")
    for f in top_files:
        h_count = len(f.get("headings", []))
        ucs = ", ".join(f.get("uc_ids", [])[:5]) or "â€”"
        print(f"     [{h_count:3d} headings] {f['relative_path']}")
        print(f"               UC-IDs: {ucs}")

    print(f"\n{'='*55}")
    print(f"  âœ… Registry saved successfully!\n")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Â§7. ENTRY POINT
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    parser = argparse.ArgumentParser(
        description=(
            "build_registry.py â€” Tá»± Ä‘á»™ng index tÃ i liá»‡u Markdown vÃ  sinh "
            "project-registry.json cho flow-design-analyst skill."
        ),
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
VÃ­ dá»¥ sá»­ dá»¥ng:
  # Index toÃ n bá»™ thÆ° má»¥c Docs/
  python build_registry.py --docs-dir ./Docs --output ./project-registry.json

  # Chá»‰ index file trong specs/ vÃ  user-stories/
  python build_registry.py --docs-dir ./Docs --output ./project-registry.json \\
      --include "specs/**" --include "user-stories/**"

  # Äáº·t tÃªn project vÃ  xem verbose
  python build_registry.py --docs-dir ./Docs --output ./project-registry.json \\
      --project-name "My E-Commerce App" --verbose
        """,
    )
    parser.add_argument(
        "--docs-dir",
        required=True,
        help="ÄÆ°á»ng dáº«n Ä‘áº¿n thÆ° má»¥c tÃ i liá»‡u cáº§n index (báº¯t buá»™c)",
    )
    parser.add_argument(
        "--output",
        default="./project-registry.json",
        help="ÄÆ°á»ng dáº«n file output JSON (máº·c Ä‘á»‹nh: ./project-registry.json)",
    )
    parser.add_argument(
        "--include",
        action="append",
        default=[],
        metavar="PATTERN",
        help="Glob pattern Ä‘á»ƒ lá»c file (cÃ³ thá»ƒ dÃ¹ng nhiá»u láº§n, vÃ­ dá»¥: 'specs/**')",
    )
    parser.add_argument(
        "--exclude-dir",
        action="append",
        default=[],
        metavar="DIR",
        help="TÃªn thÆ° má»¥c cáº§n bá» qua (vÃ­ dá»¥: 'archive', 'draft')",
    )
    parser.add_argument(
        "--project-name",
        default=None,
        help="TÃªn dá»± Ã¡n (máº·c Ä‘á»‹nh: tÃªn thÆ° má»¥c cha cá»§a docs_dir)",
    )
    parser.add_argument(
        "--verbose", "-v",
        action="store_true",
        help="Hiá»ƒn thá»‹ chi tiáº¿t quÃ¡ trÃ¬nh parsing tá»«ng file",
    )

    args = parser.parse_args()

    docs_dir = Path(args.docs_dir).resolve()
    if not docs_dir.is_dir():
        print(f"âŒ Lá»—i: --docs-dir khÃ´ng tá»“n táº¡i hoáº·c khÃ´ng pháº£i thÆ° má»¥c: {docs_dir}", file=sys.stderr)
        sys.exit(1)

    output_path = Path(args.output).resolve()

    registry = build_registry(
        docs_dir=docs_dir,
        output_path=output_path,
        include_patterns=args.include,
        exclude_dirs=args.exclude_dir,
        project_name=args.project_name,
        verbose=args.verbose,
    )

    print_report(registry)
    sys.exit(0)


if __name__ == "__main__":
    main()
